{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB10\n",
    "\n",
    "Use reinforcement learning to devise a tic-tac-toe player.\n",
    "\n",
    "### Deadlines:\n",
    "\n",
    "* Submission: [Dies Natalis Solis Invicti](https://en.wikipedia.org/wiki/Sol_Invictus)\n",
    "* Reviews: [Befana](https://en.wikipedia.org/wiki/Befana)\n",
    "\n",
    "Notes:\n",
    "\n",
    "* Reviews will be assigned  on Monday, December 4\n",
    "* You need to commit in order to be selected as a reviewer (ie. better to commit an empty work than not to commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from collections import namedtuple, defaultdict\n",
    "from random import choice\n",
    "from copy import deepcopy\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "State = namedtuple('State', ['x', 'o'])\n",
    "value_dictionary_x = defaultdict(float)\n",
    "value_dictionary_o = defaultdict(float)\n",
    "Wins = 0\n",
    "Loses = 0\n",
    "Draws = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAGIC = [2, 7, 6, \n",
    "         9, 5, 1, \n",
    "         4, 3, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_board(pos):\n",
    "    \"\"\"Nicely prints the board\"\"\"\n",
    "    for r in range(3):\n",
    "        for c in range(3):\n",
    "            i = r * 3 + c\n",
    "            if MAGIC[i] in pos.x:\n",
    "                print('X ', end='')\n",
    "            elif MAGIC[i] in pos.o:\n",
    "                print('O ', end='')\n",
    "            else:\n",
    "                print('. ', end='')\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def win(elements):\n",
    "    \"\"\"Checks is elements is winning\"\"\"\n",
    "    return any(sum(c) == 15 for c in combinations(elements, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI X player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_value_x(pos: State):\n",
    "    \"\"\"Evaluate state: +1 first player wins\"\"\"\n",
    "    if win(pos.x):\n",
    "        return 1\n",
    "    elif win(pos.o):\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make move function for X player "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_move_x(state, available):\n",
    "    \n",
    "    max_val = float('-inf')\n",
    "    move = None\n",
    "    bool = 1\n",
    "\n",
    "    for tmp in available:\n",
    "\n",
    "        next_state_x = state.x.union({tmp})\n",
    "        hashable_next_state = (frozenset(next_state_x), frozenset(state.o))\n",
    "\n",
    "        if hashable_next_state in value_dictionary_x:\n",
    "            if value_dictionary_x[hashable_next_state] > max_val:\n",
    "                max_val = value_dictionary_x[hashable_next_state]\n",
    "                move = tmp\n",
    "                bool = 0\n",
    "    \n",
    "    if bool: \n",
    "        move = choice(list(available))\n",
    "\n",
    "    return move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training phase for X player "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_game_x():\n",
    "    trajectory = list()\n",
    "    state = State(set(), set())\n",
    "    available = set(range(1, 9+1))\n",
    "    while available:\n",
    "\n",
    "        \"\"\"x turn\"\"\"\n",
    "        x = choice(list(available))\n",
    "        state.x.add(x)\n",
    "        trajectory.append(deepcopy(state))\n",
    "        available.remove(x)\n",
    "\n",
    "        if win(state.x) or not available:\n",
    "            break\n",
    "    \n",
    "        \"\"\"o turn\"\"\"\n",
    "        o = choice(list(available))\n",
    "        state.o.add(o)\n",
    "        trajectory.append(deepcopy(state))\n",
    "        available.remove(o)\n",
    "\n",
    "        if win(state.o):\n",
    "            break\n",
    "        \n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2043/1000000 [00:00<02:32, 6530.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [02:30<00:00, 6641.11it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"First training\"\"\"\n",
    "\n",
    "epsilon = 0.001\n",
    "\n",
    "for steps in tqdm(range(1_000_000)):\n",
    "    trajectory = training_game_x()\n",
    "    final_reward = state_value_x(trajectory[-1])\n",
    "    for state in trajectory:\n",
    "        hashable_state = (frozenset(state.x), frozenset(state.o))\n",
    "        value_dictionary_x[hashable_state] = value_dictionary_x[hashable_state] + epsilon * (final_reward - value_dictionary_x[hashable_state])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game tests for X player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_x():\n",
    "    trajectory = list()\n",
    "    state = State(set(), set())\n",
    "    available = set(range(1, 9+1))\n",
    "    while available:\n",
    "\n",
    "        \"\"\"x turn\"\"\"\n",
    "        x = make_move_x(state, available)\n",
    "        state.x.add(x)\n",
    "        trajectory.append(deepcopy(state))\n",
    "        available.remove(x)\n",
    "\n",
    "        if win(state.x):\n",
    "            global Wins \n",
    "            Wins += 1\n",
    "            break\n",
    "        else:\n",
    "            if not available: \n",
    "                global Draws\n",
    "                Draws +=1\n",
    "                break\n",
    "\n",
    "\n",
    "        \"\"\"o turn\"\"\"\n",
    "        o = choice(list(available))\n",
    "        state.o.add(o)\n",
    "        trajectory.append(deepcopy(state))\n",
    "        available.remove(o)\n",
    "\n",
    "        if win(state.o):\n",
    "            global Loses \n",
    "            Loses += 1\n",
    "            break\n",
    "        \n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:01<00:00, 8479.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wins: 9896,\n",
      "Loses: 0,\n",
      "Draws: 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for steps in tqdm(range(10_000)):\n",
    "    trajectory = game_x()\n",
    "\n",
    "print(f\"Wins: {Wins},\\nLoses: {Loses},\\nDraws: {Draws}\")\n",
    "\n",
    "global Loses \n",
    "Loses = 0\n",
    "\n",
    "global Draws\n",
    "Draws = 0\n",
    "\n",
    "global Wins \n",
    "Wins = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI O player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_value_o(pos: State):\n",
    "    \n",
    "    if win(pos.o):\n",
    "        return 3\n",
    "    elif win(pos.x):\n",
    "        return -1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a move function for a O player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_move_o(state, available):\n",
    "    \n",
    "    max_val = float('-inf')\n",
    "    move = None\n",
    "    bool = 1\n",
    "\n",
    "    for tmp in available:\n",
    "\n",
    "        next_state_o = state.o.union({tmp})\n",
    "        hashable_next_state = (frozenset(state.x), frozenset(next_state_o))\n",
    "\n",
    "        if hashable_next_state in value_dictionary_o:\n",
    "            if value_dictionary_o[hashable_next_state] > max_val:\n",
    "                max_val = value_dictionary_o[hashable_next_state]\n",
    "                move = tmp\n",
    "                bool = 0\n",
    "    \n",
    "    if bool: \n",
    "        move = choice(list(available))\n",
    "\n",
    "    return move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training for O player "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_game_o():\n",
    "    trajectory = list()\n",
    "    state = State(set(), set())\n",
    "    available = set(range(1, 9+1))\n",
    "    while available:\n",
    "\n",
    "        \"\"\"x turn\"\"\"\n",
    "        x = choice(list(available))\n",
    "        state.x.add(x)\n",
    "        trajectory.append(deepcopy(state))\n",
    "        available.remove(x)\n",
    "\n",
    "        if win(state.x) or not available:\n",
    "            break\n",
    "    \n",
    "        \"\"\"o turn\"\"\"\n",
    "        o = choice(list(available))\n",
    "        state.o.add(o)\n",
    "        trajectory.append(deepcopy(state))\n",
    "        available.remove(o)\n",
    "\n",
    "        if win(state.o):\n",
    "            break\n",
    "        \n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [02:28<00:00, 6750.94it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"First training\"\"\"\n",
    "\n",
    "epsilon = 0.001\n",
    "\n",
    "for steps in tqdm(range(1_000_000)):\n",
    "    trajectory = training_game_o()\n",
    "    final_reward = state_value_o(trajectory[-1])\n",
    "    for state in trajectory:\n",
    "        hashable_state = (frozenset(state.x), frozenset(state.o))\n",
    "        value_dictionary_o[hashable_state] = value_dictionary_o[hashable_state] + epsilon * (final_reward - value_dictionary_o[hashable_state])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game tests for O player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_o():\n",
    "    trajectory = list()\n",
    "    state = State(set(), set())\n",
    "    available = set(range(1, 9+1))\n",
    "    while available:\n",
    "\n",
    "        \"\"\"x turn\"\"\"\n",
    "        x = choice(list(available))\n",
    "        state.x.add(x)\n",
    "        trajectory.append(deepcopy(state))\n",
    "        available.remove(x)\n",
    "\n",
    "        if win(state.x):\n",
    "            global Loses \n",
    "            Loses += 1\n",
    "            break\n",
    "        else:\n",
    "            if not available: \n",
    "                global Draws\n",
    "                Draws +=1\n",
    "                break\n",
    "\n",
    "\n",
    "        \"\"\"o turn\"\"\"\n",
    "        o = make_move_o(state, available)\n",
    "        state.o.add(o)\n",
    "        trajectory.append(deepcopy(state))\n",
    "        available.remove(o)\n",
    "\n",
    "        if win(state.o):\n",
    "            global Wins \n",
    "            Wins += 1\n",
    "            break\n",
    "        \n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:01<00:00, 7679.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wins: 8924,\n",
      "Loses: 167,\n",
      "Draws: 909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for steps in tqdm(range(10_000)):\n",
    "    trajectory = game_o()\n",
    "\n",
    "print(f\"Wins: {Wins},\\nLoses: {Loses},\\nDraws: {Draws}\")\n",
    "\n",
    "global Loses \n",
    "Loses = 0\n",
    "\n",
    "global Draws\n",
    "Draws = 0\n",
    "\n",
    "global Wins \n",
    "Wins = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test AI X player vs AI O player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_AI():\n",
    "    trajectory = list()\n",
    "    state = State(set(), set())\n",
    "    available = set(range(1, 9+1))\n",
    "    while available:\n",
    "\n",
    "        \"\"\"x turn\"\"\"\n",
    "        x =  make_move_x(state, available)\n",
    "        state.x.add(x)\n",
    "        trajectory.append(deepcopy(state))\n",
    "        available.remove(x)\n",
    "\n",
    "        if win(state.x):\n",
    "            global Loses \n",
    "            Loses += 1\n",
    "            break\n",
    "        else:\n",
    "            if not available: \n",
    "                global Draws\n",
    "                Draws +=1\n",
    "                break\n",
    "\n",
    "\n",
    "        \"\"\"o turn\"\"\"\n",
    "        o = make_move_o(state, available)\n",
    "        state.o.add(o)\n",
    "        trajectory.append(deepcopy(state))\n",
    "        available.remove(o)\n",
    "\n",
    "        if win(state.o):\n",
    "            global Wins \n",
    "            Wins += 1\n",
    "            break\n",
    "        \n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:01<00:00, 5361.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI O player wins: 0,\n",
      "AI X player wins: 0,\n",
      "Draws: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for steps in tqdm(range(10_000)):\n",
    "    trajectory = game_AI()\n",
    "\n",
    "print(f\"AI O player wins: {Wins},\\nAI X player wins: {Loses},\\nDraws: {Draws}\")\n",
    "\n",
    "global Loses \n",
    "Loses = 0\n",
    "\n",
    "global Draws\n",
    "Draws = 0\n",
    "\n",
    "global Wins \n",
    "Wins = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining an interactive game function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_game(player):\n",
    "    trajectory = list()\n",
    "    state = State(set(), set())\n",
    "    available = set(range(1, 9+1))\n",
    "    while available:\n",
    "\n",
    "        \"\"\"x turn\"\"\"\n",
    "        if player == \"X\":\n",
    "            bool = 1\n",
    "            while bool:\n",
    "                x = int(input(\"Do your move\"))\n",
    "                if x in available:\n",
    "                    bool = 0\n",
    "                else:\n",
    "                    print(\"Move not allowed\")\n",
    "        else: \n",
    "            x = make_move_x(state, available)\n",
    "\n",
    "        state.x.add(x)\n",
    "        trajectory.append(deepcopy(state))\n",
    "        available.remove(x)\n",
    "        print_board(state)\n",
    "\n",
    "        if win(state.x):\n",
    "            print(\"X player won\")\n",
    "            break\n",
    "        else:\n",
    "            if not available: \n",
    "                print(\"It's a draw\")\n",
    "                break\n",
    "\n",
    "        \"\"\"o turn\"\"\"\n",
    "        if player == \"O\":\n",
    "            bool = 1\n",
    "            while bool:\n",
    "                o = int(input(\"Do your move\"))\n",
    "                if o in available:\n",
    "                    bool = 0\n",
    "                else:\n",
    "                    print(\"Move not allowed\")\n",
    "        else: \n",
    "            o = make_move_o(state, available)\n",
    "    \n",
    "        state.o.add(o)\n",
    "        trajectory.append(deepcopy(state))\n",
    "        available.remove(o)\n",
    "        print_board(state)\n",
    "\n",
    "        if win(state.o):\n",
    "            print(\"O player won\")\n",
    "            break\n",
    "        \n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_interface():\n",
    "    \n",
    "    print(\"Do you wanna play against AI? Y/N\")\n",
    "    input_user_1 = input()\n",
    "    \n",
    "    while input_user_1 == \"Y\":\n",
    "        print(\"Do you wanna play using X or O? X/O\")\n",
    "        input_user_2 = input()\n",
    "        print(\"Nice, let's start the game!\")\n",
    "        trajectory = interactive_game(input_user_2)\n",
    "        print(\"Do you wanna play against AI? Y/N\")\n",
    "        input_user_1 = input()\n",
    "    \n",
    "    print(\"Goodbye!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_interface()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-P-7LqQ3C-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
